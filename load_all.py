import sqlite3
import pandas as pd
import logging

logger = logging.getLogger(__name__)

class WorldCupLoader:
    """
    Module de Chargement (Load) de l'ETL.
    Responsable de la persistance des donn√©es transform√©es dans une base relationnelle SQLite.
    G√®re la d√©finition du sch√©ma (DDL), l'insertion des donn√©es et les contr√¥les de qualit√© post-chargement.
    """
    
    def __init__(self, db_path="data/worldcup.db"):
        self.db_path = db_path
        self.conn = None
    
    def connect(self):
        """√âtablit la connexion √† la base de donn√©es SQLite."""
        try:
            self.conn = sqlite3.connect(self.db_path)
            # Configuration pour acc√©der aux colonnes par leur nom (style dictionnaire)
            self.conn.row_factory = sqlite3.Row
            logger.info(f"‚úÖ Connexion √† {self.db_path} √©tablie")
        except Exception as e:
            logger.error(f"‚ùå Erreur connexion DB: {e}")
            raise
    
    def create_schema(self):
        """
        Ex√©cute le DDL (Data Definition Language).
        R√©initialise et cr√©e la structure des tables (Matchs, Stades, √âquipes, TV).
        D√©finit les cl√©s primaires et les index pour la performance.
        """
        logger.info("üèóÔ∏è  Cr√©ation du sch√©ma principal...")
        sql = """
        -- R√©initialisation propre (Idempotence)
        DROP TABLE IF EXISTS world_cup_matches;
        
        -- Table de faits principale
        CREATE TABLE world_cup_matches (
            id_match INTEGER PRIMARY KEY,
            home_team TEXT NOT NULL,
            away_team TEXT NOT NULL,
            home_result INTEGER NOT NULL,
            away_result INTEGER NOT NULL, 
            result TEXT,
            date DATE NOT NULL,
            round TEXT NOT NULL,
            city TEXT NOT NULL,
            edition TEXT NOT NULL,
            source TEXT,
            match_id_2018 INTEGER,
            stadium_id INTEGER,
            stadium_name TEXT,
            home_fifacode TEXT,
            away_fifacode TEXT
        );
        
        -- Indexation pour optimiser les requ√™tes analytiques courantes
        CREATE INDEX idx_edition ON world_cup_matches(edition);
        CREATE INDEX idx_teams ON world_cup_matches(home_team, away_team);
        
        -- Tables de dimensions (R√©f√©rentiels)
        DROP TABLE IF EXISTS stadiums;
        CREATE TABLE IF NOT EXISTS stadiums (
            stadium_id INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            city TEXT NOT NULL,
            lat REAL, lng REAL, image TEXT
        );
        
        DROP TABLE IF EXISTS teams;
        CREATE TABLE IF NOT EXISTS teams (
            team_id INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            fifaCode TEXT, iso2 TEXT, flag TEXT
        );
        
        DROP TABLE IF EXISTS tv_channels;
        CREATE TABLE IF NOT EXISTS tv_channels (
            channel_id INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            country TEXT, languages TEXT
        );
        """
        try:
            self.conn.executescript(sql)
            self.conn.commit() # Validation de la transaction
            logger.info("‚úÖ Sch√©ma cr√©√© avec succ√®s")
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation sch√©ma: {e}")
            raise
    
    def load_data(self, df):
        """
        Charge le DataFrame principal des matchs dans la base.
        G√®re le formatage des dates pour SQLite et l'alignement des colonnes.
        """
        logger.info(f"üì§ Chargement de {len(df)} matchs dans la table principale...")
        try:
            df_load = df.copy()
            
            # SQLite ne g√®re pas le type DATE natif, on force le string ISO 8601
            df_load['date'] = df_load['date'].dt.strftime('%Y-%m-%d')
            
            # Garantie que toutes les colonnes optionnelles existent (m√™me vides) pour √©viter une erreur SQL
            opt_cols = ['source', 'match_id_2018', 'stadium_id', 'stadium_name']
            for col in opt_cols:
                if col not in df_load.columns: df_load[col] = None
                
            cols_to_load = ['id_match', 'home_team', 'away_team', 'home_result', 'away_result',
                           'result', 'date', 'round', 'city', 'edition'] + opt_cols
            
            # Intersection stricte : on n'ins√®re que les colonnes pr√©sentes √† la fois dans le DF et la Table
            final_cols = [c for c in cols_to_load if c in df_load.columns]
            
            # Insertion en mode 'append' (ajout)
            df_load[final_cols].to_sql('world_cup_matches', self.conn, if_exists='append', index=False)
            self.conn.commit()
            logger.info("‚úÖ Donn√©es principales charg√©es")
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement: {e}")
            self.conn.rollback() # Annulation en cas d'erreur pour garder la base propre
            raise

    def load_additional_data(self, json_data):
        """
        Charge les tables de dimension (Stades, √âquipes, TV) depuis le JSON.
        Utilise le mode 'replace' pour ces r√©f√©rentiels.
        """
        logger.info("üì§ Chargement des donn√©es suppl√©mentaires...")
        try:
            # 1. Chargement Stades
            if 'stadiums' in json_data and json_data['stadiums']:
                pd.DataFrame(json_data['stadiums']).rename(columns={'id':'stadium_id'}).to_sql('stadiums', self.conn, if_exists='replace', index=False)
                logger.info("  - Stades charg√©s")
                
            # 2. Chargement √âquipes
            if 'teams' in json_data and json_data['teams']:
                df_t = pd.DataFrame(json_data['teams']).rename(columns={'id':'team_id'})
                # Nettoyage : suppression colonne liste 'lang' incompatible SQL direct
                if 'lang' in df_t: df_t = df_t.drop('lang', axis=1)
                df_t.to_sql('teams', self.conn, if_exists='replace', index=False)
                logger.info("  - √âquipes charg√©es")
                
            # 3. Chargement Cha√Ænes TV
            if 'tvchannels' in json_data and json_data['tvchannels']:
                df_tv = pd.DataFrame(json_data['tvchannels']).rename(columns={'id':'channel_id'})
                # Aplatissement : liste de langues -> string s√©par√© par des virgules
                if 'lang' in df_tv: df_tv['languages'] = df_tv['lang'].apply(lambda x: ','.join(x) if isinstance(x, list) else str(x))
                if 'lang' in df_tv: df_tv = df_tv.drop('lang', axis=1)
                df_tv.to_sql('tv_channels', self.conn, if_exists='replace', index=False)
                logger.info("  - Cha√Ænes TV charg√©es")
                
            self.conn.commit()
        except Exception as e:
            logger.error(f"‚ùå Erreur donn√©es supp: {e}")

    def verify_load(self):
        """
        Audit post-chargement (Data Quality Check).
        V√©rifie la volum√©trie globale, la distribution par √©dition et l'int√©grit√© temporelle.
        """
        logger.info("üîç V√©rification d√©taill√©e du chargement...")
        try:
            # 1. Volum√©trie
            res = pd.read_sql_query("SELECT COUNT(*) as t FROM world_cup_matches", self.conn)
            logger.info(f"‚úÖ Total matchs en base: {res['t'][0]}")
            
            # 2. Distribution (Coh√©rence historique)
            editions = pd.read_sql_query("SELECT edition, COUNT(*) as n FROM world_cup_matches GROUP BY edition ORDER BY edition", self.conn)
            logger.info("üìä R√©partition par √©dition:")
            for _, row in editions.iterrows():
                logger.info(f"  - {row['edition']}: {row['n']} matchs")
            
            # 3. Bornes temporelles (Test d'int√©gration)
            first = pd.read_sql_query("SELECT * FROM world_cup_matches WHERE id_match = 1", self.conn)
            if not first.empty:
                logger.info(f"ü•á Premier: {first.iloc[0]['home_team']} vs {first.iloc[0]['away_team']} ({first.iloc[0]['date']})")
                
            last = pd.read_sql_query("SELECT * FROM world_cup_matches ORDER BY id_match DESC LIMIT 1", self.conn)
            if not last.empty:
                logger.info(f"üèÜ Dernier: {last.iloc[0]['home_team']} vs {last.iloc[0]['away_team']} ({last.iloc[0]['date']})")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification: {e}")

    def close(self):
        """Fermeture propre de la connexion pour lib√©rer le fichier DB."""
        if self.conn:
            self.conn.close()
            logger.info("‚úÖ Connexion ferm√©e")
