# PrÃ©sentation : Tests du Pipeline ETL World Cup

## ğŸ¯ Objectif de cette prÃ©sentation
Comprendre l'importance des tests dans un projet Data et dÃ©couvrir comment nous avons testÃ© notre pipeline ETL de donnÃ©es footballistiques.

---

## ğŸ“‹ Qu'est-ce qu'un test en Data Engineering ?

### Pourquoi tester ?
- **Garantir la qualitÃ©** : S'assurer que le code fonctionne correctement
- **PrÃ©venir les bugs** : DÃ©tecter les erreurs avant la production
- **Faciliter l'Ã©volution** : Modifier le code en toute sÃ©curitÃ©
- **Documenter le comportement** : Les tests expliquent ce que fait le code

### Types de tests dans notre projet
- **Tests unitaires** : Tester une fonction spÃ©cifique
- **Tests d'intÃ©gration** : Tester l'interaction entre modules
- **Tests de robustesse** : Tester la gestion d'erreurs

---

## ğŸ—ï¸ Architecture de notre pipeline ETL

```
Sources de donnÃ©es â†’ Extract â†’ Transform â†’ Load â†’ Base de donnÃ©es
     â†“              â†“         â†“         â†“         â†“
   Tests          Tests     Tests     Tests     Tests
```

**4 sources de donnÃ©es** : CSV 1930-2010, CSV 2014, JSON 2018, CSV 2022

---

## ğŸ§ª Tests d'Extraction (Extract)

### Objectif
VÃ©rifier que nous pouvons lire correctement toutes les sources de donnÃ©es malgrÃ© leurs diffÃ©rences.

### Tests par source

#### ğŸ“„ Source 1 : CSV Classique (1930-2010)
```python
def test_extract_source1(self, temp_data_dir):
    extractor = WorldCupExtractor(data_dir=temp_data_dir)
    df = extractor.extract_source1("matches_19302010.csv")
    assert isinstance(df, pd.DataFrame)  # VÃ©rifie que c'est un DataFrame
    assert len(df) == 2                 # VÃ©rifie le nombre de lignes
    assert 'round' in df.columns        # VÃ©rifie les colonnes attendues
```

**Ce que Ã§a teste** : Lecture CSV standard, gestion des erreurs de fichier

#### ğŸ“„ Source 2 : CSV Complexe (2014)
```python
def test_extract_source2_encoding_fallback(self, temp_data_dir):
    # Test avec fichier encodÃ© en Latin-1
    df = extractor.extract_source2("WorldCupMatches2014_latin.csv")
    assert isinstance(df, pd.DataFrame)
```

**Ce que Ã§a teste** : Fallback automatique UTF-8 â†’ Latin-1, nettoyage des donnÃ©es bruitÃ©es

#### ğŸ“„ Source 3 : CSV Flexible (2022)
```python
def test_extract_source3_fallback_separator(self, temp_data_dir):
    # Test avec fichier utilisant point-virgule
    df = extractor.extract_source3("Fifa_world_cup_matches_semicolon.csv")
    assert isinstance(df, pd.DataFrame)
```

**Ce que Ã§a teste** : DÃ©tection automatique du sÃ©parateur, normalisation des noms de colonnes

#### ğŸ“„ Source 4 : JSON HiÃ©rarchique (2018)
```python
def test_extract_source4(self, temp_data_dir):
    data = extractor.extract_source4("data_2018.json")
    assert isinstance(data, dict)      # VÃ©rifie que c'est un dictionnaire
    assert 'groups' in data           # VÃ©rifie la structure attendue
```

**Ce que Ã§a teste** : Lecture JSON complexe avec groupes et phases finales

---

## ğŸ”„ Tests de Transformation (Transform)

### Objectif
VÃ©rifier que nous nettoyons et normalisons correctement les donnÃ©es.

### Tests de fonctions de base

#### ğŸ¯ Parsing des scores
```python
def test_parse_score_valid(self, transformer):
    home, away = transformer.parse_score("2-1")
    assert home == 2 and away == 1

def test_parse_score_invalid(self, transformer):
    home, away = transformer.parse_score("invalid")
    assert home is None and away is None
```

**Ce que Ã§a teste** : Regex universelle pour diffÃ©rents formats de scores

#### ğŸ† Normalisation des Ã©quipes
```python
def test_normalize_team(self, transformer):
    assert transformer.normalize_team("West Germany") == "Germany"
    assert transformer.normalize_team("Brazil") == "Brazil"
```

**Ce que Ã§a teste** : Mappings pour gÃ©rer les noms d'Ã©quipes variables

#### ğŸŸï¸ Normalisation des villes
```python
def test_normalize_city(self, transformer):
    assert transformer.normalize_city("PARIS") == "Paris"
    assert transformer.normalize_city("Rio de Janeiro") == "Rio De Janeiro"
```

**Ce que Ã§a teste** : Nettoyage et standardisation des noms de villes

### Tests par source

#### Source 1 : Nettoyage complet
- Parsing des scores depuis la colonne "score"
- Normalisation Ã©quipes, villes, rounds
- Calcul automatique du rÃ©sultat (home/away/draw)

#### Source 2 : Extraction ciblÃ©e
- SÃ©lection des bonnes colonnes (Home Team Name, Away Team Goals, etc.)
- Gestion des dates au format "14 Jun 2014 - 13:00"

#### Source 3 : Mapping dynamique
- DÃ©tection automatique des colonnes de scores
- Parsing spÃ©cial des dates ("01 Jan" â†’ 2022-01-01)

#### Source 4 : Structure complexe
- Extraction des matchs de groupes ET phases finales
- Mapping des IDs d'Ã©quipes vers noms rÃ©els
- Liaison avec les stades

---

## ğŸ’¾ Tests de Chargement (Load)

### Objectif
VÃ©rifier que nous sauvegardons correctement les donnÃ©es en base.

```python
def test_load_data(self, loader, sample_df):
    loader.connect()
    loader.create_schema()
    loader.load_data(sample_df)

    # VÃ©rifier que les donnÃ©es sont bien en base
    df_loaded = pd.read_sql_query("SELECT * FROM world_cup_matches", loader.conn)
    assert len(df_loaded) == 2
    assert df_loaded.iloc[0]['home_team'] == 'Brazil'
```

**Ce que Ã§a teste** :
- Connexion Ã  SQLite
- CrÃ©ation de la table avec le bon schÃ©ma
- Insertion des donnÃ©es
- Gestion des transactions et rollback en cas d'erreur

---

## ğŸ”— Tests d'IntÃ©gration

### Objectif
VÃ©rifier que tout le pipeline fonctionne ensemble.

```python
def test_full_pipeline_execution(self, temp_workspace):
    # ExÃ©cuter le pipeline complet
    run_etl_pipeline()

    # VÃ©rifier les rÃ©sultats
    db_path = Path("data/worldcup.db")
    assert db_path.exists()

    csv_path = Path("data/processed/worldcup_clean.csv")
    assert csv_path.exists()

    # VÃ©rifier le contenu de la base
    conn = sqlite3.connect(str(db_path))
    df = pd.read_sql_query("SELECT * FROM world_cup_matches", conn)
    assert len(df) > 0
```

**Ce que Ã§a teste** : Le pipeline complet de bout en bout

---

## ğŸ“Š MÃ©triques de qualitÃ©

### Couverture des tests
- **extract.py**   : 89% 
- **transform.py** : 74% 
- **load.py**      : 100%
- **Total**        : 79%

### Nombre de tests
- **76 tests** au total
- Tests unitaires, d'intÃ©gration, de robustesse

---

## ğŸ“ LeÃ§ons apprises pour les Data Learners

### 1. **L'importance des tests**
- Un code non testÃ© est un code risquÃ©
- Les tests donnent confiance pour modifier le code
- Ils servent de documentation vivante

### 2. **StratÃ©gie de test**
- Tester les cas nominaux (Ã§a marche)
- Tester les cas d'erreur (Ã§a plante proprement)
- Tester les cas limites (donnÃ©es manquantes, formats Ã©tranges)

### 3. **Outils utilisÃ©s**
- **pytest** : Framework de test Python
- **pandas** : Pour manipuler les DataFrames de test
- **sqlite3** : Pour tester la base de donnÃ©es
- **tempfile** : Pour crÃ©er des fichiers temporaires de test

### 4. **Bonnes pratiques**
- Un test = une fonctionnalitÃ©
- Noms descriptifs (test_extract_source1_file_not_found)
- Tests indÃ©pendants les uns des autres
- Utiliser des fixtures pour rÃ©utiliser le code

---

## ğŸš€ Pour aller plus loin

### Tests avancÃ©s Ã  implÃ©menter
- Tests de performance (vitesse d'exÃ©cution)
- Tests avec de gros volumes de donnÃ©es
- Tests d'API si on expose les donnÃ©es
- Tests automatisÃ©s dans un pipeline CI/CD

