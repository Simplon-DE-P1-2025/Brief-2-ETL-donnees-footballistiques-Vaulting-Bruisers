"""
ETL Pipeline - FIFA World Cup Matches (1930-2022)
Pipeline complet : Extract -> Transform -> Load

Ce script agit comme le point d'entr√©e (Orchestrateur) du projet.
Il coordonne les interactions entre les modules d'extraction, de transformation et de chargement.
"""
import logging
from pathlib import Path
from config import setup_logging
from extract import WorldCupExtractor
from transform import WorldCupTransformer
from load import WorldCupLoader

def run_etl_pipeline():
    """
    Fonction principale d'orchestration.
    Ex√©cute s√©quentiellement les √©tapes E-T-L avec gestion des erreurs et logging centralis√©.
    """
    # Initialisation du syst√®me de logs
    setup_logging()
    logger = logging.getLogger(__name__)
    
    logger.info("="*70)
    logger.info("üöÄ D√âBUT DU PIPELINE ETL")
    logger.info("="*70)
    
    try:
        # =====================================================================
        # PHASE 1 : EXTRACTION (Ingestion)
        # Lecture des sources h√©t√©rog√®nes (CSV historiques, JSON, Fichiers correctifs)
        # =====================================================================
        extractor = WorldCupExtractor(data_dir="data/raw")
        
        # Chargement des datasets bruts en m√©moire (DataFrames)
        df1 = extractor.extract_source1("matches_1930-2010.csv")
        df2 = extractor.extract_source2("WorldCupMatches2014.csv")
        df3 = extractor.extract_source3("Fifa_world_cup_matches.csv")
        json4 = extractor.extract_source4("data_2018.json")
        dates_1930_2010 = extractor.extract_historical_dates("dates_1930_2010.txt")
        
        # Chargement du fichier de r√©f√©rence pour la correction des villes 2022
        cities_22 = extractor.extract_cities_2022("cities_2022.csv")
        
        # =====================================================================
        # PHASE 2 : TRANSFORMATION
        # Nettoyage, Normalisation, Enrichissement et Consolidation
        # =====================================================================
        transformer = WorldCupTransformer()
        
        # Transformation unitaire de chaque source (Parsing dates, scores, noms)
        df_c1 = transformer.transform_source1(df1)
        if dates_1930_2010 is not None:
            df_c1 = transformer.enrich_with_historical_dates(df_c1, dates_1930_2010)
        df_c2 = transformer.transform_source2(df2)
        df_c3 = transformer.transform_source3(df3)
        df_c4 = transformer.transform_source4(json4)

        # Application des r√®gles m√©tier sp√©cifiques (Enrichissement)
        # 1. Correction des villes 2022 via jointure externe
        if cities_22 is not None:
            df_c3 = transformer.enrich_2022_with_cities(df_c3, cities_22)
        
        # 2. Ajout des m√©tadonn√©es (Stades/√âquipes) pour 2018
        if not df_c4.empty:
            df_c4 = transformer.enrich_with_stadiums(df_c4, json4)
            df_c4 = transformer.enrich_with_teams_info(df_c4, json4)
            
        # Fusion des datasets et g√©n√©ration de l'ID unique
        df_final = transformer.consolidate([df_c1, df_c2, df_c3, df_c4])
        
        # Audit Qualit√© des Donn√©es (Data Quality)
        transformer.analyze_results(df_final)
        
        if not transformer.validate(df_final):
            logger.warning("‚ö†Ô∏è Probl√®mes de validation d√©tect√©s (pipeline continue)")
            
        # =====================================================================
        # PHASE 3 : CHARGEMENT (Load)
        # Persistance des donn√©es nettoy√©es dans le Data Warehouse (SQLite)
        # =====================================================================
        loader = WorldCupLoader(db_path="data/worldcup.db")
        loader.connect()
        
        # R√©initialisation du sch√©ma (DDL)
        loader.create_schema()
        
        # Insertion des donn√©es (DML)
        loader.load_data(df_final)             # Table de faits (Matchs)
        loader.load_additional_data(json4)     # Tables de dimensions (Stades, etc.)
        
        # V√©rification finale post-chargement
        loader.verify_load()
        loader.close()
        
        # Export Flat File (CSV) pour audit ou usage BI l√©ger
        df_final.to_csv("data/processed/worldcup_clean.csv", index=False)
        logger.info("‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS")
        
    except Exception as e:
        # Gestion globale des exceptions critiques
        logger.error(f"‚ùå ERREUR PIPELINE: {e}")
        import traceback
        traceback.print_exc()

# =====================================================================
# POINT D'ENTR√âE (MAIN)
# =====================================================================
if __name__ == "__main__":
    # Pr√©paration de l'environnement d'ex√©cution (arborescence fichiers)
    Path("data/raw").mkdir(parents=True, exist_ok=True)
    Path("data/processed").mkdir(parents=True, exist_ok=True)
    
    # Lancement de l'orchestrateur
    run_etl_pipeline()